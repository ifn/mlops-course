version: "3"

services: 
  api:
    build: ./api/
    image: med-consultant-api:latest
    env_file:
      - ./api/.env
    volumes:
      - ./api:/api
      - ./app:/api/app
    depends_on:
      - database
      - rabbitmq
    restart: unless-stopped

  web-proxy:
    build: ./nginx
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - api
    restart: unless-stopped

  rabbitmq:
    image: rabbitmq:4.2.1-management-alpine
    ports:
      - "5672:5672"
      - "15672:15672"
    env_file:
      - ./rabbitmq/.env
    volumes:
      - rmq_data:/var/lib/rabbitmq
    restart: on-failure
    healthcheck:
      test: rabbitmq-diagnostics -q ping
      interval: 30s
      timeout: 30s
      retries: 3

  database:
    image: postgres:18.1-alpine
    ports:
      - "5432:5432"
    env_file:
      - ./database/.env
    volumes:
      - pg_data:/var/lib/postgresql/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 10s
      retries: 3

  ml_worker:
    build: ./ml_worker/
    image: ml-worker-llm-proxy:latest
    restart: unless-stopped
    env_file:
      - ./ml_worker/.env
    volumes:
      - ./ml_worker:/ml_worker
      - ./app:/ml_worker/app
    depends_on:
      - rabbitmq
      - ollama
    deploy:
      mode: replicated
      replicas: 2

  ml_task_result_saver:
    build: ./ml_task_result_saver/
    image: ml-task-result-saver:latest
    container_name: ml-task-result-saver
    restart: unless-stopped
    env_file:
      - ./ml_task_result_saver/.env
    volumes:
      - ./ml_task_result_saver:/ml_task_result_saver
      - ./app:/ml_task_result_saver/app
    depends_on:
      - rabbitmq
      - database

  ollama:
    dns:
      - 8.8.8.8
      - 8.8.4.4
    image: ollama/ollama:0.12.0-rc1
    container_name: ollama
    ports:
      - "22434:11434"
    volumes:
      - ollama_data:/root/.ollama

volumes:
  pg_data:
  rmq_data:
  ollama_data:
